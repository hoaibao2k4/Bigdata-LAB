{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ea6488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = r\"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = r\"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "215b727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in d:\\uit_courses\\bigdata\\lab 2\\.venv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in d:\\uit_courses\\bigdata\\lab 2\\.venv\\lib\\site-packages (from pyspark) (0.10.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15ac4d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession created successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Cấu hình Spark\n",
    "spark_conf = (\n",
    "    SparkConf()\n",
    "    .setAppName(\"MovieRatingSpark\")\n",
    "    .setMaster(\"local[*]\")\n",
    ")\n",
    "\n",
    "# Tạo SparkContext\n",
    "spark_context = SparkContext.getOrCreate(conf=spark_conf)\n",
    "\n",
    "# Tạo SparkSession\n",
    "spark_session = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"MovieRatingSpark\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "if spark_session:\n",
    "    print(\"SparkSession created successfully.\")\n",
    "else:\n",
    "    print(\"Error: Failed to create SparkSession.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d67f07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "movies.txt:\n",
      "1001,The Godfather (1972),Crime|Drama\n",
      "1002,The Shawshank Redemption (1994),Drama\n",
      "1003,Schindler's List (1993),Biography|Drama|History\n",
      "1004,Raging Bull (1980),Biography|Drama|Sport\n",
      "1005,Casablanca (1942),Drama|Romance|War\n",
      "\n",
      "ratings_1.txt:\n",
      "7,1020,4.5,1577836800\n",
      "23,1015,3.5,1577923200\n",
      "45,1030,4.0,1578009600\n",
      "12,1047,3.0,1578096000\n",
      "38,1012,4.5,1578182400\n",
      "\n",
      "ratings_2.txt:\n",
      "12,1012,3.5,1577837800\n",
      "34,1039,4.0,1577924200\n",
      "27,1043,4.5,1578010600\n",
      "8,1020,3.0,1578097000\n",
      "19,1050,4.0,1578183400\n",
      "\n",
      "users.txt:\n",
      "12,1012,3.5,1577837800\n",
      "34,1039,4.0,1577924200\n",
      "27,1043,4.5,1578010600\n",
      "8,1020,3.0,1578097000\n",
      "19,1050,4.0,1578183400\n",
      "\n",
      "occupation.txt:\n",
      "1,Programmer\n",
      "2,Doctor\n",
      "3,Engineer\n",
      "4,Teacher\n",
      "5,Lawyer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "rs_path = \"./resource/\"\n",
    "\n",
    "# Đọc file movies và rating{1,2} với RDD\n",
    "movies_rdd = spark_context.textFile(os.path.join(rs_path, \"movies.txt\"))\n",
    "ratings_1_rdd = spark_context.textFile(os.path.join(rs_path, \"ratings_1.txt\"))\n",
    "ratings_2_rdd = spark_context.textFile(os.path.join(rs_path, \"ratings_2.txt\"))\n",
    "users_rdd = spark_context.textFile(os.path.join(rs_path, \"users.txt\"))\n",
    "occupation_rdd = spark_context.textFile(os.path.join(rs_path, \"occupation.txt\"))\n",
    "\n",
    "\n",
    "# Show data\n",
    "if movies_rdd and ratings_1_rdd and ratings_2_rdd:\n",
    "    print(\"\\nmovies.txt:\")\n",
    "    for line in movies_rdd.take(5):\n",
    "        print(line)\n",
    "    print(\"\\nratings_1.txt:\")\n",
    "    for line in ratings_1_rdd.take(5):\n",
    "        print(line)\n",
    "    print(\"\\nratings_2.txt:\")\n",
    "    for line in ratings_2_rdd.take(5):\n",
    "        print(line)\n",
    "    print(\"\\nusers.txt:\")\n",
    "    for line in ratings_2_rdd.take(5):\n",
    "        print(line)\n",
    "    print(\"\\noccupation.txt:\")\n",
    "    for line in occupation_rdd.take(5):\n",
    "        print(line)\n",
    "else:\n",
    "    print(\"Error: Failed to load RDD files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54862f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After parsing:\n",
      "Movie: 1001 The Godfather (1972)\n",
      "Movie: 1002 The Shawshank Redemption (1994)\n",
      "Movie: 1003 Schindler's List (1993)\n",
      "Movie: 1004 Raging Bull (1980)\n",
      "Movie: 1005 Casablanca (1942)\n"
     ]
    }
   ],
   "source": [
    "# Parse movies\n",
    "def parse_movie(line):\n",
    "    parts = line.split(',', 2)\n",
    "    movie_id = int(parts[0])\n",
    "    title = parts[1]\n",
    "    genres = parts[2] if len(parts) > 2 else \"\"\n",
    "    genres_list = genres.split('|') if genres else []\n",
    "    return (movie_id, title)\n",
    "movies_parse = movies_rdd.map(parse_movie)\n",
    "\n",
    "print(\"After parsing:\")\n",
    "for col in movies_parse.take(5):\n",
    "    print(f\"Movie: {col[0]} {col[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcdce689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1:\n",
      "Rating: 4.5, year: 2020\n",
      "Rating: 3.5, year: 2020\n",
      "Rating: 4.0, year: 2020\n",
      "Rating: 3.0, year: 2020\n",
      "Rating: 4.5, year: 2020\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# Parse ratings\n",
    "def parse_rating(line):\n",
    "    parts = line.split(',')\n",
    "    user_id = int(parts[0])\n",
    "    movie_id = int(parts[1])\n",
    "    rating = float(parts[2])\n",
    "    timestamp = int(parts[3])\n",
    "    try:\n",
    "        year = datetime.datetime.fromtimestamp(timestamp).year\n",
    "    except:\n",
    "        year = 2000  # Default year\n",
    "    return (year, rating)\n",
    "\n",
    "ratings_1_parse = ratings_1_rdd.map(parse_rating)\n",
    "ratings_2_parse = ratings_2_rdd.map(parse_rating)\n",
    "\n",
    "#show rating 1\n",
    "print(\"Rating 1:\")\n",
    "for col in ratings_1_parse.take(5):\n",
    "    print(f\"Rating: {col[1]}, year: {col[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c7758e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \n",
      "User: 1 3\n",
      "User: 2 7\n",
      "User: 3 2\n",
      "User: 4 10\n",
      "User: 5 1\n"
     ]
    }
   ],
   "source": [
    "def parse_user(line):\n",
    "    parts = line.split(',', 4)\n",
    "    user_id = int(parts[0])\n",
    "    gender = parts[1]\n",
    "    age = int(parts[2])\n",
    "    occupation_id = int(parts[3])\n",
    "    return (user_id, occupation_id)\n",
    "user_parse = users_rdd.map(parse_user)\n",
    "\n",
    "#show user\n",
    "print(\"User: \")\n",
    "for col in user_parse.take(5):\n",
    "    print(f\"User: {col[0]} {col[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e5ccb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging: 184\n",
      "2020 - (TotalRatings: 184), AverageRating: 3.75\n"
     ]
    }
   ],
   "source": [
    "# Merge ratings 1 && 2\n",
    "#  (year, rating)\n",
    "all_ratings = ratings_1_parse.union(ratings_2_parse)\n",
    "print(f\"After merging: {all_ratings.count()}\")\n",
    "\n",
    "# (year, (rating, 1))\n",
    "ratings_pair = all_ratings.map(\n",
    "    lambda x: (x[0], (x[1], 1))\n",
    ")\n",
    "# tính sum + count => # (year, (sumRating, count))\n",
    "ratings_stats = ratings_pair.reduceByKey(\n",
    "    lambda a, b: (a[0] + b[0], a[1] + b[1])\n",
    ")\n",
    "#(year, (avg, count))\n",
    "rating_year_avg = ratings_stats.mapValues(\n",
    "    lambda x: (x[0] / x[1], x[1])\n",
    ")\n",
    "\n",
    "def formatter(x):\n",
    "    return f\"{x:.2f}\" if x is not None else \"NA\"\n",
    "\n",
    "for year, (avg, count) in rating_year_avg.take(10):\n",
    "    print(\n",
    "        f\"{year} - (TotalRatings: {count}), AverageRating: {formatter(avg)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69960e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear\n",
    "spark_context.stop()\n",
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
